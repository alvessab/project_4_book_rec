{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#countvectorizer model\n",
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#tf-idf model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/goodreads_final_bagowords.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3713db80",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a49307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bookTitle\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effbf0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Author\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61acc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Genre\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad1d14",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8560fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer model\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df['bag_of_words'])\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "print(cosine_sim)\n",
    "\n",
    "indices = pd.Series(df['bookTitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = count_matrix.toarray()\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bd784",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a218bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4924008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc813ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(bookTitle, cosine_sim = cosine_sim):\n",
    "    recommended_book = []\n",
    "    idx = indices[indices == bookTitle].index[0]\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "    top_10_indices = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    for i in top_10_indices:\n",
    "        recommended_book.append(list(df['bookTitle'])[i])\n",
    "        \n",
    "    return recommended_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend('To Kill a Mockingbird')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c925c",
   "metadata": {},
   "source": [
    "## TF- IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2a86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataframe\n",
    "rating_min = 3.0\n",
    "\n",
    "df_fil = df.loc[df['bookRating'] >= rating_min]\n",
    "df_fil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://practicaldatascience.co.uk/data-science/how-to-create-content-recommendations-using-tf-idf\n",
    "#bag of words is already made, but this will also down-weight common words that appear across documents\n",
    "tfidf = TfidfVectorizer(stop_words='english',smooth_idf=True)\n",
    "\n",
    "# numbers to calculate similarities\n",
    "tfidf_matrix = tfidf.fit_transform(df_fil['bag_of_words']).todense()\n",
    "\n",
    "#calculate cosine matrix\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_similarities)\n",
    "\n",
    "indices = pd.Series(df_fil['bookTitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get recommendations based on tf-idf and cosine_similarities\n",
    "\n",
    "def recommend_tf(bookTitle, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    recommended_book = []\n",
    "    recommended_book_url = []\n",
    "    recommended_book_image= []\n",
    "    recommended_book_author = []\n",
    "    recommended_book_rating =[]\n",
    "    recommended_book_descrip =[]\n",
    "    recommended_book_genre =[]\n",
    "    \n",
    "    idx = indices[indices == bookTitle].index[0]\n",
    "    \n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending = False)\n",
    "    \n",
    "    top_10_indices = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    for i in top_10_indices:\n",
    "        recommended_book.append(list(df_fil['bookTitle'])[i])\n",
    "        recommended_book_url.append(list(df_fil['url'])[i])\n",
    "        recommended_book_image.append(list(df_fil['bookImage'])[i])\n",
    "        recommended_book_author.append(list(df_fil['Author'])[i])\n",
    "        recommended_book_rating.append(list(df_fil['bookRating'])[i])\n",
    "        recommended_book_descrip.append(list(df_fil['bookDesc'])[i])\n",
    "        recommended_book_genre.append(list(df_fil['Genre'])[i])\n",
    "        recommended_book_score.append(score_series[i])\n",
    "\n",
    "    data = {'Title': recommended_book,\n",
    "           'Author': recommended_book_author,\n",
    "            'Genre': recommended_book_genre,\n",
    "            'Description' : recommended_book_descrip,\n",
    "            'Rating':recommended_book_rating,\n",
    "            'URL': recommended_book_url,\n",
    "            'Image': recommended_book_image,\n",
    "            'Score': recommended_book_score\n",
    "           }\n",
    "    rec_df = pd.DataFrame(data)\n",
    "    \n",
    "    return rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_tf('Twilight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181e1758",
   "metadata": {},
   "source": [
    "## Process Model for flask app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a3c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc18f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8863 entries, 0 to 8862\n",
      "Columns: 8864 entries, index to 8862\n",
      "dtypes: float64(8863), int64(1)\n",
      "memory usage: 599.4 MB\n"
     ]
    }
   ],
   "source": [
    "#code that stays consistent\n",
    "df = pd.read_csv(\"../data/goodreads_final_bagowords.csv\")\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english',smooth_idf=True)\n",
    "tfidf_matrix = tfidf.fit_transform(df['bag_of_words']).todense()\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "#make into dataframe\n",
    "df_data = pd.DataFrame(cosine_similarities).reset_index()\n",
    "\n",
    "#string columns names required for parquet file\n",
    "#df_data.columns = df_data.columns.astype(str)\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08446c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine_similarities is a numpy.ndarray\n",
    "type(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13bae4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/goodreads_cos_data.npy\", cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54fdbebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.load(\"../data/goodreads_cos_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e77ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00402374 0.0138527  ... 0.00703557 0.00161726 0.01776498]\n",
      " [0.00402374 1.         0.         ... 0.03376514 0.01499929 0.01502661]\n",
      " [0.0138527  0.         1.         ... 0.         0.01281669 0.01778946]\n",
      " [0.00876162 0.         0.03632484 ... 0.         0.00672774 0.02887838]\n",
      " [0.02501998 0.0097621  0.02640575 ... 0.         0.00894217 0.01068593]]\n"
     ]
    }
   ],
   "source": [
    "print(arr1[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6488c355",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://book-rec-nlp.s3.amazonaws.com/goodreads_cos_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/93/69nrl93d0k36xslv9kn84gcc0000gn/T/ipykernel_93108/2741926748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'https://book-rec-nlp.s3.amazonaws.com/goodreads_cos_data.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://book-rec-nlp.s3.amazonaws.com/goodreads_cos_data.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "link= 'https://book-rec-nlp.s3.amazonaws.com/goodreads_cos_data.npy'\n",
    "arr1 = np.load(link)\n",
    "print(arr1[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a74fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f97b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef287dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1= np.load(s3.open(\"book-rec-nlp/goodreads_cos_data.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd51677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00402374 0.0138527  ... 0.00703557 0.00161726 0.01776498]\n",
      " [0.00402374 1.         0.         ... 0.03376514 0.01499929 0.01502661]\n",
      " [0.0138527  0.         1.         ... 0.         0.01281669 0.01778946]\n",
      " [0.00876162 0.         0.03632484 ... 0.         0.00672774 0.02887838]\n",
      " [0.02501998 0.0097621  0.02640575 ... 0.         0.00894217 0.01068593]]\n"
     ]
    }
   ],
   "source": [
    "print(arr1[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4726d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24be36bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3client = boto3.client('s3', region_name='us-east-1', config=Config(signature_version=UNSIGNED))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f84dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with io.BytesIO(s3client.get_object(Bucket=\"book-rec-nlp\", Key=\"goodreads_cos_data.npy\")[\"Body\"].read()) as f:\n",
    "    f.seek(0)  # rewind the file\n",
    "    arr1 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4abdeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.00402374 0.0138527  ... 0.00703557 0.00161726 0.01776498]\n",
      " [0.00402374 1.         0.         ... 0.03376514 0.01499929 0.01502661]\n",
      " [0.0138527  0.         1.         ... 0.         0.01281669 0.01778946]\n",
      " [0.00876162 0.         0.03632484 ... 0.         0.00672774 0.02887838]\n",
      " [0.02501998 0.0097621  0.02640575 ... 0.         0.00894217 0.01068593]]\n"
     ]
    }
   ],
   "source": [
    "print(arr1[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7104208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee475887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#variable\n",
    "bookTitle = 'To Kill a Mockingbird'\n",
    "\n",
    "\n",
    "#variable reliant code\n",
    "indices = pd.Series(df_par['bookTitle'])\n",
    "\n",
    "recommended_book = []\n",
    "recommended_book_url = []\n",
    "recommended_book_image= []\n",
    "recommended_book_author = []\n",
    "recommended_book_rating =[]\n",
    "recommended_book_descrip =[]\n",
    "recommended_book_genre =[]\n",
    "recommended_book_score =[]\n",
    "\n",
    "idx = indices[indices == bookTitle].index[0]\n",
    "\n",
    "score_series = pd.Series(arr1[idx]).sort_values(ascending = False)\n",
    "\n",
    "top_10_indices = list(score_series.iloc[1:11].index)\n",
    "\n",
    "for i in top_10_indices:\n",
    "    recommended_book.append(list(df_par['bookTitle'])[i])\n",
    "    recommended_book_url.append(list(df_par['url'])[i])\n",
    "    recommended_book_image.append(list(df_par['bookImage'])[i])\n",
    "    recommended_book_author.append(list(df_par['Author'])[i])\n",
    "    recommended_book_rating.append(list(df_par['bookRating'])[i])\n",
    "    recommended_book_descrip.append(list(df_par['bookDesc'])[i])\n",
    "    recommended_book_genre.append(list(df_par['Genre'])[i])\n",
    "    recommended_book_score.append(score_series[i])\n",
    "\n",
    "data = {'Title': recommended_book,\n",
    "       'Author': recommended_book_author,\n",
    "        'Genre': recommended_book_genre,\n",
    "        'Description' : recommended_book_descrip,\n",
    "        'Rating':recommended_book_rating,\n",
    "        'URL': recommended_book_url,\n",
    "        'Image': recommended_book_image,\n",
    "        'Score': recommended_book_score\n",
    "       }\n",
    "rec_df = pd.DataFrame(data)\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef729758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore variables\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11537c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29211ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9312cd59",
   "metadata": {},
   "source": [
    "### Explore data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd335ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
